//
//  AUAudioRecorder.m
//  AVDemo
//
//  Created by SeacenLiu on 2020/2/1.
//  Copyright Â© 2020 SeacenLiu. All rights reserved.
//

#import "AUAudioRecorder.h"
#import "SCAudioSession.h"
#import "AUAudioRecorder+Interruption.h"
#import "AUExtAudioFile+Write.h"
#import "AUExtAudioFile+Read.h"
#import "NSString+Path.h"

static const AudioUnitElement inputElement = 1;
static const AudioUnitElement outputElement = 0;

/** AUGraph éŸ³é¢‘æµæµç¨‹ï¼ˆä»¥æ­¤ä¸ºå‡†ï¼‰
 * ğŸ™ -> RemoteIO(InputElement) -[stereoStreamFormat]->
 * AudioConverter -[clientFormat32float]-> MixerUnit(Bus0)
 * -[clientFormat32float]-> RemoteIO(OutputElement) -> ğŸ”ˆ
 */

@interface AUAudioRecorder ()

@property (nonatomic, copy)   NSString*          filePath;
@property (nonatomic, assign) Float64            sampleRate;
@property (nonatomic, assign) UInt32             channels;

@property (nonatomic, assign) AUGraph            auGraph;
@property (nonatomic, assign) AUNode             ioNode;
@property (nonatomic, assign) AudioUnit          ioUnit;
@property (nonatomic, assign) AUNode             playerNode;
@property (nonatomic, assign) AudioUnit          playerUnit;
@property (nonatomic, assign) AUNode             mixerNode;
@property (nonatomic, assign) AudioUnit          mixerUnit;
@property (nonatomic, assign) AUNode             convertNode;
@property (nonatomic, assign) AudioUnit          convertUnit;

@property (nonatomic, assign, getter=isEnablePlayWhenRecord) BOOL enablePlayWhenRecord;
@property (nonatomic, assign, getter=isEnableMixer) BOOL enableMixer;

@end

#define BufferList_cache_size (1024*10*5)
@implementation AUAudioRecorder
{
    AudioBufferList* _bufferList;
    AUExtAudioFile*  _dataWriter;

    NSString*        _backgroundPath;
    AUExtAudioFile*  _dataReader;
    AudioStreamBasicDescription _mixerStreamDesForInput;    // æ··éŸ³å™¨çš„è¾“å…¥æ•°æ®æ ¼å¼
    AudioBufferList* _mixerBufferList;
}
#pragma mark - life cycle
- (instancetype)initWithPath:(NSString*)path {
    if (self = [self init]) {
        // å±æ€§åˆå§‹åŒ–
        _filePath = path;
        _sampleRate = 44100.0;
        _channels = 2;
        
        self.enablePlayWhenRecord = NO;
        
        _bufferList = CreateBufferList(2, NO, BufferList_cache_size);
        
        // --------------------------------------------------------------
        _mixerBufferList = CreateBufferList(2, NO, BufferList_cache_size);
        self.enableMixer = YES;
        _backgroundPath = [NSString bundlePath:@"background.mp3"];
        UInt32 bytesPerSample = 4;  // è¦ä¸ä¸‹é¢mFormatFlags å¯¹åº”
        AudioStreamBasicDescription absd;
        absd.mFormatID          = kAudioFormatLinearPCM;
        absd.mFormatFlags       = kAudioFormatFlagsNativeFloatPacked;
        absd.mBytesPerPacket    = bytesPerSample;
        absd.mFramesPerPacket   = 1;
        absd.mBytesPerFrame     = 4;
        absd.mChannelsPerFrame  = 2;
        absd.mBitsPerChannel    = 8 * bytesPerSample;
        absd.mSampleRate        = 0;
        
        _dataReader = [[AUExtAudioFile alloc] initWithReadPath:path adsb:absd canrepeat:NO];
        _mixerStreamDesForInput = _dataReader.clientABSD;
        // --------------------------------------------------------------
        
        // éŸ³é¢‘ä¼šè¯è®¾ç½®
        [[SCAudioSession sharedInstance] setCategory:AVAudioSessionCategoryPlayAndRecord];
        [[SCAudioSession sharedInstance] setPreferredSampleRate:_sampleRate];
        [[SCAudioSession sharedInstance] setActive:YES];
        [[SCAudioSession sharedInstance] addRouteChangeListener];
        
        // éŸ³é¢‘æ‰“æ–­å¤„ç†
        [self addAudioSessionInterruptedObserver];
        
        // åˆå§‹åŒ–éŸ³é¢‘å›¾
        [self createAudioUnitGraph];
        
        [self setUpFilePlayer];
        
        [self checkFormat];
    }
    return self;
}

- (void)dealloc {
    [self destroyAudioUnitGraph];
    DestroyBufferList(_bufferList);
}

#pragma mark - public method
- (void)start {
    AudioStreamBasicDescription clientFormat;
    UInt32 fSize = sizeof (clientFormat);
    memset(&clientFormat, 0, sizeof(clientFormat));
//    CheckStatus(AudioUnitGetProperty(_ioUnit,
//                                     kAudioUnitProperty_StreamFormat,
//                                     kAudioUnitScope_Output,
//                                     inputElement,
//                                     &clientFormat,
//                                     &fSize),
//                @"AudioUnitGetProperty on failed",
//                YES);
    CheckStatus(AudioUnitGetProperty(_mixerUnit,
                         kAudioUnitProperty_StreamFormat,
                         kAudioUnitScope_Output,
                         outputElement,
                         &clientFormat,
                         &fSize),
    @"AudioUnitGetProperty on failed",
    YES);
    NSLog(@"---------------------- clientFormat --------------------------");
    /*
     2020-02-03 23:25:52.783710+0800 AVDemo[57007:1653650] ---------------------- clientFormat --------------------------
     Sample Rate:              44100
     Format ID:                 lpcm
     Format Flags:                 C
     Bytes per Packet:             4
     Frames per Packet:            1
     Bytes per Frame:              4
     Channels per Frame:           2
     Bits per Channel:            16
     Reserved:                     0
     */
    
    printAudioStreamFormat(clientFormat);
    _dataWriter = [[AUExtAudioFile alloc] initWithWritePath:_filePath adsb:clientFormat fileTypeId:AUAudioFileTypeCAF];
//    _dataWriter = [[AUExtAudioFile alloc] initWithWritePath:_filePath adsb:clientFormat fileTypeId:AUAudioFileTypeM4A];
    
    OSStatus status = AUGraphStart(_auGraph);
    CheckStatus(status, @"å¯åŠ¨éŸ³é¢‘å›¾å¤±è´¥", YES);
}

- (void)stop {
    OSStatus status = AUGraphStop(_auGraph);
    CheckStatus(status, @"åœæ­¢éŸ³é¢‘å›¾å¤±è´¥", YES);
    // å…³é—­æ–‡ä»¶å’Œé‡Šæ”¾å¯¹è±¡
    [_dataWriter closeFile];
}

#pragma mark - Audio Unit Graph
- (void)createAudioUnitGraph {
    // 1. å®ä¾‹åŒ–éŸ³é¢‘å•å…ƒå›¾å¯¹è±¡
    OSStatus status = NewAUGraph(&_auGraph);
    CheckStatus(status, @"å®ä¾‹åŒ–AUGraphå¯¹è±¡å¤±è´¥", YES);
    // 2. æ·»åŠ éŸ³é¢‘ç»“ç‚¹(AUGraphAddNode)
    [self addAudioUnitNodes];
    // 3. æ‰“å¼€éŸ³é¢‘å•å…ƒå›¾(æ¿€æ´»Audio Unit Node)
    status = AUGraphOpen(_auGraph);
    CheckStatus(status, @"AUGraphå¯¹è±¡æ‰“å¼€å¤±è´¥", YES);
    // 4. ä»ç»“ç‚¹ä¸­è·å–éŸ³é¢‘å•å…ƒ(AUGraphNodeInfo)
    [self getUnitsFromNodes];
    // 5. (*)è®¾ç½®éŸ³é¢‘å•å…ƒå±æ€§
    [self setAudioUnitProperties];
    // 6. è¿æ¥éŸ³é¢‘å•å…ƒ
    [self makeNodeConnections];
    // 7. è®¾ç½®æ•°æ®æºæ–¹æ³•
    [self setupRenderCallback];
    // 7. (*)å±•ç¤ºéŸ³é¢‘å•å…ƒå›¾(ç©ºçš„...)
    CAShow(_auGraph);
    // 8. åˆå§‹åŒ–éŸ³é¢‘å›¾
    status = AUGraphInitialize(_auGraph);
    CheckStatus(status, @"åˆå§‹åŒ–AUGraphå¤±è´¥", YES);
}

- (void)addAudioUnitNodes {
    OSStatus status = noErr;
    AudioComponentDescription ioDescription;
    bzero(&ioDescription, sizeof(ioDescription));
    ioDescription.componentType = kAudioUnitType_Output;
    ioDescription.componentSubType = kAudioUnitSubType_RemoteIO;
    ioDescription.componentManufacturer = kAudioUnitManufacturer_Apple;
    status = AUGraphAddNode(_auGraph, &ioDescription, &_ioNode);
    CheckStatus(status, @"RemoteIOç»“ç‚¹æ·»åŠ å¤±è´¥", YES);
    
    if (self.isEnableMixer) {
        AudioComponentDescription playerDescription;
        bzero(&playerDescription, sizeof(playerDescription));
        playerDescription.componentManufacturer = kAudioUnitManufacturer_Apple;
        playerDescription.componentType = kAudioUnitType_Generator;
        playerDescription.componentSubType = kAudioUnitSubType_AudioFilePlayer;
        status = AUGraphAddNode(_auGraph, &playerDescription, &_playerNode);
        CheckStatus(status, @"Could not add Player node to AUGraph", YES);
        
        AudioComponentDescription mixerDescription;
        bzero(&mixerDescription, sizeof(mixerDescription));
        mixerDescription.componentType = kAudioUnitType_Mixer;
        mixerDescription.componentSubType = kAudioUnitSubType_MultiChannelMixer;
        mixerDescription.componentManufacturer = kAudioUnitManufacturer_Apple;
        status = AUGraphAddNode(_auGraph, &mixerDescription, &_mixerNode);
        CheckStatus(status, @"Mixerç»“ç‚¹æ·»åŠ å¤±è´¥", YES);
        
        AudioComponentDescription convertDescription;
        bzero(&convertDescription, sizeof(convertDescription));
        convertDescription.componentType = kAudioUnitType_FormatConverter;
        convertDescription.componentSubType = kAudioUnitSubType_AUConverter;
        convertDescription.componentManufacturer = kAudioUnitManufacturer_Apple;
        status = AUGraphAddNode(_auGraph, &convertDescription, &_convertNode);
        CheckStatus(status, @"convertç»“ç‚¹æ·»åŠ å¤±è´¥", YES);
    }
}

- (void)getUnitsFromNodes {
    OSStatus status = noErr;
    status = AUGraphNodeInfo(_auGraph, _ioNode, NULL, &_ioUnit);
    CheckStatus(status, @"è·å–RemoteIOå•å…ƒå¤±è´¥", YES);
    if (self.isEnableMixer) {
        status = AUGraphNodeInfo(_auGraph, _playerNode, NULL, &_playerUnit);
        CheckStatus(status, @"è·å–playerå•å…ƒå¤±è´¥", YES);
        status = AUGraphNodeInfo(_auGraph, _mixerNode, NULL, &_mixerUnit);
        CheckStatus(status, @"è·å–Mixerå•å…ƒå¤±è´¥", YES);
        status = AUGraphNodeInfo(_auGraph, _convertNode, NULL, &_convertUnit);
        CheckStatus(status, @"è·å–Convertå•å…ƒå¤±è´¥", YES);
    }
}

- (void)setAudioUnitProperties {
    OSStatus status = noErr;
    // æ¿€æ´» RemoteIO çš„ IO åŠŸèƒ½
    UInt32 enableIO = 1;
    status = AudioUnitSetProperty(_ioUnit,
                                  kAudioOutputUnitProperty_EnableIO,
                                  kAudioUnitScope_Input,
                                  inputElement,
                                  &enableIO,
                                  sizeof(enableIO));
    CheckStatus(status, @"éº¦å…‹é£ å¯åŠ¨å¤±è´¥", YES);
    status = AudioUnitSetProperty(_ioUnit,
                                  kAudioOutputUnitProperty_EnableIO,
                                  kAudioUnitScope_Output,
                                  outputElement,
                                  &enableIO,
                                  sizeof(enableIO));
    CheckStatus(status, @"æ‰¬å£°å™¨ å¯åŠ¨å¤±è´¥", YES);
    // è®¾ç½® RemoteIO åˆ‡ç‰‡æœ€å¤§å¸§æ•°ï¼ˆè¾“å‡ºç«¯å…¨å±€åŸŸï¼‰
    // AudioUnitRender()å‡½æ•°åœ¨å¤„ç†è¾“å…¥æ•°æ®æ—¶ï¼Œæœ€å¤§çš„è¾“å…¥ååé‡
    UInt32 maximumFramesPerSlice = 4096;
    status = AudioUnitSetProperty(_ioUnit,
                                  kAudioUnitProperty_MaximumFramesPerSlice,
                                  kAudioUnitScope_Global,
                                  outputElement,
                                  &maximumFramesPerSlice,
                                  sizeof (maximumFramesPerSlice));
    CheckStatus(status, @"RemoteIO åˆ‡ç‰‡æœ€å¤§å¸§æ•°è®¾ç½®å¤±è´¥", YES);
    
    // è®¾ç½®éŸ³é¢‘å›¾ä¸­çš„éŸ³é¢‘æµæ ¼å¼
    AudioStreamBasicDescription micInputStreamFormat;
    AudioFormatFlags formatFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked;
    micInputStreamFormat = linearPCMStreamDes(formatFlags,
                                         _sampleRate,
                                         2,
                                         sizeof(UInt16));
    NSLog(@"---------------------- micInputStreamFormat --------------------------");
    printAudioStreamFormat(micInputStreamFormat);
    
    // RemoteIO æµæ ¼å¼
    AudioUnitSetProperty(_ioUnit,
                         kAudioUnitProperty_StreamFormat,
                         kAudioUnitScope_Output,
                         inputElement,
                         &micInputStreamFormat,
                         sizeof(micInputStreamFormat));
//    if (self.isEnablePlayWhenRecord) {
        AudioUnitSetProperty(_ioUnit,
                             kAudioUnitProperty_StreamFormat,
                             kAudioUnitScope_Input,
                             outputElement,
                             &micInputStreamFormat,
                             sizeof(micInputStreamFormat));
//    }
    
    if (self.isEnableMixer) {
        // player
        AudioStreamBasicDescription playerStreamFormat; // ç«‹ä½“å£°æµæ ¼å¼
        UInt32 bytesPerSample = sizeof(Float32);
        bzero(&playerStreamFormat, sizeof(playerStreamFormat));
        playerStreamFormat.mFormatID          = kAudioFormatLinearPCM;
        playerStreamFormat.mFormatFlags       = kAudioFormatFlagsNativeFloatPacked | kAudioFormatFlagIsNonInterleaved;
        playerStreamFormat.mBytesPerPacket    = bytesPerSample;
        playerStreamFormat.mFramesPerPacket   = 1;
        playerStreamFormat.mBytesPerFrame     = bytesPerSample;
        playerStreamFormat.mChannelsPerFrame  = 2;                    // 2 indicates stereo
        playerStreamFormat.mBitsPerChannel    = 8 * bytesPerSample;
        playerStreamFormat.mSampleRate        = 41000;//48000.0;
        status = AudioUnitSetProperty(_playerUnit,
                                      kAudioUnitProperty_StreamFormat,
                                      kAudioUnitScope_Output,
                                      0,
                                      &playerStreamFormat,
                                      sizeof(playerStreamFormat));
        CheckStatus(status, @"playerStreamFormat error", YES);
        
        // convert
        CheckStatus(AudioUnitSetProperty(_convertUnit,
                             kAudioUnitProperty_StreamFormat,
                             kAudioUnitScope_Input,
                             0,
                             &playerStreamFormat,
                             sizeof(playerStreamFormat)),
        @"è½¬æ¢å™¨å™¨è¾“å…¥æµæ ¼å¼é…ç½®å¤±è´¥",YES);
        CheckStatus(AudioUnitSetProperty(_convertUnit,
                             kAudioUnitProperty_StreamFormat,
                             kAudioUnitScope_Output,
                             0,
                             &micInputStreamFormat,
                             sizeof(micInputStreamFormat)),
        @"è½¬æ¢å™¨å™¨è¾“å‡ºæµæ ¼å¼é…ç½®å¤±è´¥",YES);
        
        // mixer
        UInt32 mixerInputcount = 2;
        CheckStatus(AudioUnitSetProperty(_mixerUnit,
                                         kAudioUnitProperty_ElementCount,
                                         kAudioUnitScope_Input,
                                         0,
                                         &mixerInputcount,
                                         sizeof(mixerInputcount)),
                    @"é…ç½®æ··éŸ³å™¨éŸ³è½¨æ•°å¤±è´¥", YES);
        
        CheckStatus(AudioUnitSetProperty(_mixerUnit,
                                         kAudioUnitProperty_SampleRate,
                                         kAudioUnitScope_Output,
                                         0,
                                         &_sampleRate,
                                         sizeof(_sampleRate)),
                    @"é…ç½®æ··éŸ³å™¨è¾“å‡ºé‡‡æ ·ç‡å¤±è´¥", YES);
        
        for (int i=0; i < mixerInputcount; ++i) {
            status = AudioUnitSetProperty(_mixerUnit,
                                          kAudioUnitProperty_StreamFormat,
                                          kAudioUnitScope_Input,
                                          i,
                                          &micInputStreamFormat,
                                          sizeof(micInputStreamFormat));
            if (status != noErr) {
                NSLog(@"AudioUnitSetProperty kAudioUnitProperty_StreamFormat %d",status);
            }
            
//            AURenderCallbackStruct callback;
//            callback.inputProc = mixerInputDataCallback;
//            callback.inputProcRefCon = (__bridge void*)self;
//            status = AudioUnitSetProperty(_mixerUnit, kAudioUnitProperty_SetRenderCallback, kAudioUnitScope_Input, i, &callback, sizeof(callback));
//            if (status != noErr) {
//                NSLog(@"AudioUnitSetProperty kAudioUnitProperty_SetRenderCallback %d",status);
//            }
        }
        
        status = AudioUnitSetProperty(_mixerUnit,
                                      kAudioUnitProperty_StreamFormat,
                                      kAudioUnitScope_Output,
                                      0,
                                      &micInputStreamFormat,
                                      sizeof(micInputStreamFormat));
        if (status != noErr) {
            NSLog(@"AudioUnitSetProperty kAudioUnitProperty_StreamFormat %d",status);
        }
    
        CheckStatus(AudioUnitSetParameter(_mixerUnit,
                                          kMultiChannelMixerParam_Volume,
                                          kAudioUnitScope_Input,
                                          0,
                                          1,
                                          0),
                    @"Input Volume Error", YES);
        CheckStatus(AudioUnitSetParameter(_mixerUnit,
                                          kMultiChannelMixerParam_Volume,
                                          kAudioUnitScope_Input,
                                          1,
                                          0.5,
                                          0),
                    @"Input Volume Error", YES);
        
//        AudioStreamBasicDescription mixerStreamFormat;
//        AudioFormatFlags mixerFlags = kAudioFormatFlagIsSignedInteger | kAudioFormatFlagIsPacked;
//        mixerStreamFormat = linearPCMStreamDes(mixerFlags,
//                                               _sampleRate,
//                                               _channels,
//                                               sizeof(UInt16));
    }
}

- (void)makeNodeConnections {
    OSStatus status = noErr;
    if (self.isEnablePlayWhenRecord) {
        status = AUGraphConnectNodeInput(_auGraph,
                                         _ioNode, inputElement,
                                         _ioNode, outputElement);
    }
    
    if (self.isEnableMixer) {
        
        status = AUGraphConnectNodeInput(_auGraph, _ioNode, 1, _mixerNode, 0);
        
        status = AUGraphConnectNodeInput(_auGraph, _playerNode, 0, _convertNode, 0);
        status = AUGraphConnectNodeInput(_auGraph, _convertNode, 0, _mixerNode, 1);
        
//        status = AUGraphConnectNodeInput(_auGraph, _mixerNode, 0, _ioNode, 0);
    }
    
//    AURenderCallbackStruct finalRenderProc;
//    finalRenderProc.inputProc = &saveOutputCallback;
//    finalRenderProc.inputProcRefCon = (__bridge void *)self;
//    // AUGraphSetNodeInputCallback
//    status = AudioUnitSetProperty(_ioUnit,
//                                  kAudioOutputUnitProperty_SetInputCallback,
//                                  kAudioUnitScope_Output,
//                                  1,
//                                  &finalRenderProc,
//                                  sizeof(finalRenderProc));
//    CheckStatus(status, @"è®¾ç½® RemoteIO è¾“å‡ºå›è°ƒå¤±è´¥", YES);
    
    AURenderCallbackStruct finalRenderProc;
    finalRenderProc.inputProc = &saveMixerOutputCallback;
    finalRenderProc.inputProcRefCon = (__bridge void *)self;
    status = AUGraphSetNodeInputCallback(_auGraph,
                                         _ioNode,
                                         outputElement,
                                         &finalRenderProc);
    CheckStatus(status, @"è®¾ç½® RemoteIO è¾“å‡ºå›è°ƒå¤±è´¥", YES);
}

- (void)setupRenderCallback {
//    OSStatus status;
//    AURenderCallbackStruct finalRenderProc;
//    finalRenderProc.inputProc = &saveOutputCallback;
//    finalRenderProc.inputProcRefCon = (__bridge void *)self;
//    status = AudioUnitSetProperty(_ioUnit,
//                                  kAudioOutputUnitProperty_SetInputCallback,
//                                  kAudioUnitScope_Output,
//                                  inputElement,
//                                  &finalRenderProc,
//                                  sizeof(finalRenderProc));
//    CheckStatus(status, @"è®¾ç½® RemoteIO è¾“å‡ºå›è°ƒå¤±è´¥", YES);
}

- (void)destroyAudioUnitGraph {
    AUGraphStop(_auGraph);
    AUGraphUninitialize(_auGraph);
    AUGraphClose(_auGraph);
    AUGraphRemoveNode(_auGraph, _ioNode);
    AUGraphRemoveNode(_auGraph, _mixerNode);
    AUGraphRemoveNode(_auGraph, _convertNode);
    DisposeAUGraph(_auGraph);
    _ioNode = 0;
    _ioUnit = NULL;
    _mixerNode = 0;
    _mixerUnit = NULL;
    _convertNode = 0;
    _convertUnit = NULL;
    _auGraph = NULL;
}

#pragma mark - æ ¸å¿ƒå›è°ƒå‡½æ•°
static OSStatus saveMixerOutputCallback(void *inRefCon,
                               AudioUnitRenderActionFlags *ioActionFlags,
                               const AudioTimeStamp *inTimeStamp,
                               UInt32 inBusNumber,
                               UInt32 inNumberFrames,
                               AudioBufferList *ioData) {
    OSStatus result = noErr;
    __unsafe_unretained AUAudioRecorder *recorder = (__bridge AUAudioRecorder *)inRefCon;
    
//    AudioUnitRender(recorder->_convertUnit, ioActionFlags, inTimeStamp, 0, inNumberFrames, ioData);
    
    AudioUnitRender(recorder->_mixerUnit,
                    ioActionFlags,
                    inTimeStamp,
                    0, // 1
                    inNumberFrames,
                    recorder->_bufferList);

    // å¼‚æ­¥å‘æ–‡ä»¶ä¸­å†™å…¥æ•°æ®
    result = [recorder->_dataWriter writeFrames:inNumberFrames
                                 toBufferData:recorder->_bufferList
                                        async:YES];
    
    return result;
}

static OSStatus saveOutputCallback(void *inRefCon,
                               AudioUnitRenderActionFlags *ioActionFlags,
                               const AudioTimeStamp *inTimeStamp,
                               UInt32 inBusNumber,
                               UInt32 inNumberFrames,
                               AudioBufferList *ioData) {
    OSStatus result = noErr;
    __unsafe_unretained AUAudioRecorder *recorder = (__bridge AUAudioRecorder *)inRefCon;
    
    AudioUnitRender(recorder->_ioUnit,
                    ioActionFlags,
                    inTimeStamp,
                    inBusNumber, // 1
                    inNumberFrames,
                    recorder->_bufferList);

    // å¼‚æ­¥å‘æ–‡ä»¶ä¸­å†™å…¥æ•°æ®
    result = [recorder->_dataWriter writeFrames:inNumberFrames
                                 toBufferData:recorder->_bufferList
                                        async:YES];
    
    return result;
}

//static OSStatus mixerInputDataCallback(void *inRefCon,
//                                       AudioUnitRenderActionFlags *ioActionFlags,
//                                       const AudioTimeStamp *inTimeStamp,
//                                       UInt32 inBusNumber,
//                                       UInt32 inNumberFrames,
//                                       AudioBufferList *ioData) {
//    OSStatus result = noErr;
//    __unsafe_unretained AUAudioRecorder *recorder = (__bridge AUAudioRecorder *)inRefCon;
//
//    if (inBusNumber == 0) {     // ä»£è¡¨å½•éŸ³
//        // å°†å½•éŸ³çš„æ•°æ®å¡«å……è¿›æ¥
//        result = AudioUnitRender(recorder->_ioUnit, ioActionFlags, inTimeStamp, 1, inNumberFrames, ioData);
//    } else if (inBusNumber == 1){   // ä»£è¡¨éŸ³é¢‘æ–‡ä»¶
//        // ä»éŸ³é¢‘æ–‡ä»¶ä¸­è¯»å–æ•°æ®å¹¶å¡«å……è¿›æ¥
////        result = [recorder->_dataReader readFrames:&inNumberFrames toBufferData:ioData];
//        result = AudioUnitRender(recorder->_convertUnit, ioActionFlags, inTimeStamp, 0, inNumberFrames, ioData);
//    }
//
//    return result;
//}

- (void)setUpFilePlayer {
    OSStatus status = noErr;
    AudioFileID musicFile;
    NSURL *url = [NSURL URLWithString:_backgroundPath];
    CFURLRef songURL = (__bridge  CFURLRef)url;
    // æ‰“å¼€è¾“å…¥çš„éŸ³é¢‘æ–‡ä»¶
    status = AudioFileOpenURL(songURL, kAudioFileReadPermission, 0, &musicFile);
    CheckStatus(status, @"Open AudioFile... ", YES);
    
    // åœ¨å…¨å±€åŸŸçš„è¾“å‡ºå…ƒç´ ä¸­è®¾ç½®æ’­æ”¾å™¨å•å…ƒç›®æ ‡æ–‡ä»¶
    status = AudioUnitSetProperty(_playerUnit,
                                  kAudioUnitProperty_ScheduledFileIDs,
                                  kAudioUnitScope_Global,
                                  0,
                                  &musicFile,
                                  sizeof(musicFile));
    CheckStatus(status, @"Tell AudioFile Player Unit Load Which File... ", YES);
    
    // é€šè¿‡éŸ³é¢‘æ–‡ä»¶è·å–éŸ³é¢‘æ•°æ®æµçš„æ ¼å¼
    AudioStreamBasicDescription fileASBD;
    UInt32 propSize = sizeof(fileASBD);
    status = AudioFileGetProperty(musicFile,
                                  kAudioFilePropertyDataFormat,
                                  &propSize,
                                  &fileASBD);
    CheckStatus(status, @"get the audio data format from the file... ", YES);
    
    // é€šè¿‡éŸ³é¢‘æ–‡ä»¶è·å–éŸ³é¢‘æ•°æ®åŒ…çš„æ•°é‡
    UInt64 nPackets;
    UInt32 propsize = sizeof(nPackets);
    AudioFileGetProperty(musicFile,
                         kAudioFilePropertyAudioDataPacketCount,
                         &propsize,
                         &nPackets);
    
    // å‘ŠçŸ¥æ–‡ä»¶æ’­æ”¾å•å…ƒä»0å¼€å§‹æ’­æ”¾æ•´ä¸ªæ–‡ä»¶
    ScheduledAudioFileRegion rgn;
    memset (&rgn.mTimeStamp, 0, sizeof(rgn.mTimeStamp));
    rgn.mTimeStamp.mFlags = kAudioTimeStampSampleTimeValid;
    rgn.mTimeStamp.mSampleTime = 0;
    rgn.mCompletionProc = NULL;
    rgn.mCompletionProcUserData = NULL;
    rgn.mAudioFile = musicFile;
    rgn.mLoopCount = 2;
    rgn.mStartFrame = 0;
    rgn.mFramesToPlay = (UInt32)nPackets * fileASBD.mFramesPerPacket;
    status = AudioUnitSetProperty(_playerUnit,
                                  kAudioUnitProperty_ScheduledFileRegion,
                                  kAudioUnitScope_Global,
                                  0,
                                  &rgn,
                                  sizeof(rgn));
    CheckStatus(status, @"Set Region... ", YES);
    
    // è®¾ç½®æ–‡ä»¶æ’­æ”¾å•å…ƒå‚æ•°ä¸ºé»˜è®¤å€¼
    UInt32 defaultVal = 0;
    status = AudioUnitSetProperty(_playerUnit,
                                  kAudioUnitProperty_ScheduledFilePrime,
                                  kAudioUnitScope_Global,
                                  0,
                                  &defaultVal,
                                  sizeof(defaultVal));
    CheckStatus(status, @"Prime Player Unit With Default Value... ", YES);
    
    // è®¾ç½®ä½•æ—¶å¼€å§‹æ’­æ”¾(æ’­æ”¾æ¨¡å¼)(-1 sample time means next render cycle)
    AudioTimeStamp startTime;
    memset (&startTime, 0, sizeof(startTime));
    startTime.mFlags = kAudioTimeStampSampleTimeValid;
    startTime.mSampleTime = -1;
    status = AudioUnitSetProperty(_playerUnit,
                                  kAudioUnitProperty_ScheduleStartTimeStamp,
                                  kAudioUnitScope_Global,
                                  0,
                                  &startTime,
                                  sizeof(startTime));
    CheckStatus(status, @"set Player Unit Start Time... ", YES);
}

#pragma mark - Check
- (void)checkFormat {
    AudioStreamBasicDescription clientFormat;
    UInt32 fSize = sizeof(clientFormat);
    memset(&clientFormat, 0, sizeof(clientFormat));
    CheckStatus(AudioUnitGetProperty(_convertUnit,
                                     kAudioUnitProperty_StreamFormat,
                                     kAudioUnitScope_Input,
                                     0,
                                     &clientFormat,
                                     &fSize),
                @"AudioUnitGetProperty on failed",
                YES);
    NSLog(@"============== convert input ==============");
    printAudioStreamFormat(clientFormat);
    
    memset(&clientFormat, 0, sizeof(clientFormat));
    CheckStatus(AudioUnitGetProperty(_convertUnit,
                                     kAudioUnitProperty_StreamFormat,
                                     kAudioUnitScope_Output,
                                     0,
                                     &clientFormat,
                                     &fSize),
                @"AudioUnitGetProperty on failed",
                YES);
    NSLog(@"============== convert output ==============");
    printAudioStreamFormat(clientFormat);
    
    memset(&clientFormat, 0, sizeof(clientFormat));
    CheckStatus(AudioUnitGetProperty(_ioUnit,
                                     kAudioUnitProperty_StreamFormat,
                                     kAudioUnitScope_Output,
                                     1,
                                     &clientFormat,
                                     &fSize),
                @"AudioUnitGetProperty on failed",
                YES);
    NSLog(@"============== io 1 output ==============");
    printAudioStreamFormat(clientFormat);
    
    memset(&clientFormat, 0, sizeof(clientFormat));
    CheckStatus(AudioUnitGetProperty(_ioUnit,
                                     kAudioUnitProperty_StreamFormat,
                                     kAudioUnitScope_Input,
                                     0,
                                     &clientFormat,
                                     &fSize),
                @"AudioUnitGetProperty on failed",
                YES);
    NSLog(@"============== io 0 input ==============");
    printAudioStreamFormat(clientFormat);
    
    memset(&clientFormat, 0, sizeof(clientFormat));
    CheckStatus(AudioUnitGetProperty(_mixerUnit,
                                     kAudioUnitProperty_StreamFormat,
                                     kAudioUnitScope_Output,
                                     0,
                                     &clientFormat,
                                     &fSize),
                @"AudioUnitGetProperty on failed",
                YES);
    NSLog(@"============== mixer output ==============");
    printAudioStreamFormat(clientFormat);
    
    CAShow(_auGraph);
}

@end
